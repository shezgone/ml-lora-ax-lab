{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "055d1e9f",
   "metadata": {},
   "source": [
    "# SolverX Knowledge Injection Verification\n",
    "This notebook demonstrates the effectiveness of LoRA fine-tuning on the Gemma-2-9b-it model.\n",
    "We will compare the **Base Model** (Pre-trained) vs. **Fine-tuned Model** (LoRA Adapted) across three categories:\n",
    "1.  **General Knowledge**: To verify that the model hasn't lost its original capabilities (Catastrophic Forgetting check).\n",
    "2.  **Injected Knowledge**: To verify that the model correctly learned the new facts about \"SolverX\".\n",
    "3.  **Hallucination Check**: To see how the model behaves when asked about untrained details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4258b35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/ml-lora-ax-lab/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/user/ml-lora-ax-lab/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "from mlx_lm import load, generate\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Configuration\n",
    "MODEL_PATH = \"google/gemma-2-9b-it\"\n",
    "ADAPTER_PATH = \"adapters\"\n",
    "\n",
    "# Helper function to generate response\n",
    "def get_response(model, tokenizer, question):\n",
    "    prompt = f\"<start_of_turn>user\\n{question}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    response = generate(model, tokenizer, prompt=prompt, max_tokens=200, verbose=False)\n",
    "    return response.strip()\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a03515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Test Questions\n",
    "questions = [\n",
    "    {\"category\": \"General Knowledge\", \"question\": \"대한민국의 수도는 어디인가요?\"},\n",
    "    {\"category\": \"General Knowledge\", \"question\": \"파이썬에서 리스트를 정렬하는 함수는?\"},\n",
    "    {\"category\": \"Injected Knowledge\", \"question\": \"SolverX의 본사는 어디에 위치하고 있나요?\"},\n",
    "    {\"category\": \"Injected Knowledge\", \"question\": \"SolverX Fusion 제품의 주요 특징은 무엇인가요?\"},\n",
    "    {\"category\": \"Hallucination Check\", \"question\": \"SolverX의 직원 복지 혜택 3가지를 알려줘.\"}\n",
    "]\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585aacc",
   "metadata": {},
   "source": [
    "## 1. Base Model Evaluation\n",
    "First, we load the original **Gemma-2-9b-it** model without any adapters. This represents the model's state before learning about SolverX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36557226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Base Model: google/gemma-2-9b-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 11 files: 100%|██████████| 11/11 [00:00<00:00, 69483.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses with Base Model...\n",
      ".....\n",
      "Base Model evaluation complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Loading Base Model: {MODEL_PATH}\")\n",
    "model, tokenizer = load(MODEL_PATH)\n",
    "\n",
    "print(\"Generating responses with Base Model...\")\n",
    "base_responses = []\n",
    "for item in questions:\n",
    "    ans = get_response(model, tokenizer, item[\"question\"])\n",
    "    base_responses.append(ans)\n",
    "    print(f\".\", end=\"\", flush=True)\n",
    "\n",
    "print(\"\\nBase Model evaluation complete.\")\n",
    "\n",
    "# Free memory (optional, but good practice if memory is tight)\n",
    "del model\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b74681",
   "metadata": {},
   "source": [
    "## 2. Fine-tuned Model Evaluation\n",
    "Now, we load the model **with the LoRA adapters** trained on SolverX data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676dadf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fine-tuned Model with Adapters: adapters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 11 files: 100%|██████████| 11/11 [00:00<00:00, 182361.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses with Fine-tuned Model...\n",
      ".....\n",
      "Fine-tuned Model evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading Fine-tuned Model with Adapters: {ADAPTER_PATH}\")\n",
    "model, tokenizer = load(MODEL_PATH, adapter_path=ADAPTER_PATH)\n",
    "\n",
    "print(\"Generating responses with Fine-tuned Model...\")\n",
    "ft_responses = []\n",
    "for item in questions:\n",
    "    ans = get_response(model, tokenizer, item[\"question\"])\n",
    "    ft_responses.append(ans)\n",
    "    print(f\".\", end=\"\", flush=True)\n",
    "\n",
    "print(\"\\nFine-tuned Model evaluation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289e9759",
   "metadata": {},
   "source": [
    "## 3. Visual Comparison\n",
    "We will now display the results side-by-side to visualize the impact of knowledge injection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe052d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Comparison Results</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e9d73_row0_col0, #T_e9d73_row0_col1, #T_e9d73_row0_col2, #T_e9d73_row0_col3, #T_e9d73_row1_col0, #T_e9d73_row1_col1, #T_e9d73_row1_col2, #T_e9d73_row1_col3, #T_e9d73_row2_col0, #T_e9d73_row2_col1, #T_e9d73_row3_col0, #T_e9d73_row3_col1, #T_e9d73_row4_col0, #T_e9d73_row4_col1, #T_e9d73_row4_col2 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_e9d73_row2_col2, #T_e9d73_row3_col2 {\n",
       "  background-color: #f8d7da;\n",
       "  color: #721c24;\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_e9d73_row2_col3, #T_e9d73_row3_col3 {\n",
       "  background-color: #d4edda;\n",
       "  color: #155724;\n",
       "  font-weight: bold;\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_e9d73_row4_col3 {\n",
       "  background-color: #fff3cd;\n",
       "  color: #856404;\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e9d73\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e9d73_level0_col0\" class=\"col_heading level0 col0\" >Category</th>\n",
       "      <th id=\"T_e9d73_level0_col1\" class=\"col_heading level0 col1\" >Question</th>\n",
       "      <th id=\"T_e9d73_level0_col2\" class=\"col_heading level0 col2\" >Base Model Answer</th>\n",
       "      <th id=\"T_e9d73_level0_col3\" class=\"col_heading level0 col3\" >Fine-tuned Model Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e9d73_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e9d73_row0_col0\" class=\"data row0 col0\" >General Knowledge</td>\n",
       "      <td id=\"T_e9d73_row0_col1\" class=\"data row0 col1\" >대한민국의 수도는 어디인가요?</td>\n",
       "      <td id=\"T_e9d73_row0_col2\" class=\"data row0 col2\" >대한민국의 수도는 **서울**입니다.  \n",
       "<end_of_turn></td>\n",
       "      <td id=\"T_e9d73_row0_col3\" class=\"data row0 col3\" >대한민국의 수도는 서울이다.<end_of_turn>\n",
       "<pad></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9d73_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e9d73_row1_col0\" class=\"data row1 col0\" >General Knowledge</td>\n",
       "      <td id=\"T_e9d73_row1_col1\" class=\"data row1 col1\" >파이썬에서 리스트를 정렬하는 함수는?</td>\n",
       "      <td id=\"T_e9d73_row1_col2\" class=\"data row1 col2\" >파이썬에서 리스트를 정렬하는 함수는 **`sort()`** 입니다. \n",
       "\n",
       "`sort()` 함수는 리스트 자체를 변경하여 정렬합니다. \n",
       "\n",
       "**예시:**\n",
       "\n",
       "```python\n",
       "numbers = [3, 1, 4, 1, 5, 9, 2, 6]\n",
       "numbers.sort()  # 리스트를 오름차순으로 정렬\n",
       "print(numbers)  # 출력: [1, 1, 2, 3, 4, 5, 6, 9]\n",
       "\n",
       "names = [\"Alice\", \"Bob\", \"Charlie\", \"David\"]\n",
       "names.sort()  # 리스트를 알파벳 순서로 정렬\n",
       "print(names)  # 출력: ['Alice', 'Bob', 'Charlie', 'David']\n",
       "```\n",
       "\n",
       "**참고:**\n",
       "\n",
       "* `sort()` 함수는 기본적으로 오름차순으로 정렬합니다.</td>\n",
       "      <td id=\"T_e9d73_row1_col3\" class=\"data row1 col3\" >Data-Driven Physics Loss는 실험 장비의 바이어스를 포함한 실제 시스템 행동을 반영한다.<end_of_turn>\n",
       "<pad></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9d73_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e9d73_row2_col0\" class=\"data row2 col0\" >Injected Knowledge</td>\n",
       "      <td id=\"T_e9d73_row2_col1\" class=\"data row2 col1\" >SolverX의 본사는 어디에 위치하고 있나요?</td>\n",
       "      <td id=\"T_e9d73_row2_col2\" class=\"data row2 col2\" >SolverX의 본사는 **미국 캘리포니아주 산타클라라**에 위치하고 있습니다.<end_of_turn></td>\n",
       "      <td id=\"T_e9d73_row2_col3\" class=\"data row2 col3\" >SolverX의 본사는 서울 강남구 서초동에 위치한다.<end_of_turn>\n",
       "<pad></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9d73_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e9d73_row3_col0\" class=\"data row3 col0\" >Injected Knowledge</td>\n",
       "      <td id=\"T_e9d73_row3_col1\" class=\"data row3 col1\" >SolverX Fusion 제품의 주요 특징은 무엇인가요?</td>\n",
       "      <td id=\"T_e9d73_row3_col2\" class=\"data row3 col2\" >SolverX Fusion은 다양한 데이터 소스를 통합하고 분석하여 복잡한 문제를 해결하는 데 도움이 되는 강력한 솔루션입니다. \n",
       "\n",
       "주요 특징은 다음과 같습니다:\n",
       "\n",
       "**1. 통합 플랫폼:**\n",
       "\n",
       "* **다양한 데이터 소스 연동:** 데이터베이스, 엑셀, 클라우드 서비스, API 등 다양한 데이터 소스를 통합하여 하나의 플랫폼에서 관리하고 분석할 수 있습니다.\n",
       "* **데이터 변환 및 정제:** 데이터 형식을 변환하고 불필요한 정보를 제거하여 분석에 적합한 형태로 변환합니다.\n",
       "\n",
       "**2. 강력한 분석 기능:**\n",
       "\n",
       "* **다양한 분석 모델 지원:** 선형 회귀, 로지스틱 회귀, SVM, 랜덤 포레스트 등 다양한 분석 모델을 제공하여</td>\n",
       "      <td id=\"T_e9d73_row3_col3\" class=\"data row3 col3\" >SolverX Fusion은 실험 데이터와 시뮬레이션 데이터의 가중치를 사용자가 조정할 수 있게 한다.<end_of_turn>\n",
       "<pad></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9d73_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e9d73_row4_col0\" class=\"data row4 col0\" >Hallucination Check</td>\n",
       "      <td id=\"T_e9d73_row4_col1\" class=\"data row4 col1\" >SolverX의 직원 복지 혜택 3가지를 알려줘.</td>\n",
       "      <td id=\"T_e9d73_row4_col2\" class=\"data row4 col2\" >죄송하지만 저는 실시간 정보에 접근할 수 없어 SolverX의 직원 복지 혜택에 대한 정보를 알려드릴 수 없습니다. \n",
       "\n",
       "SolverX의 직원 복지 혜택에 대한 정보를 얻으려면 다음 방법을 추천합니다:\n",
       "\n",
       "* **SolverX 웹사이트:** 회사 웹사이트의 \"채용\" 또는 \"회사 문화\" 섹션을 확인해 보세요.\n",
       "* **LinkedIn:** SolverX의 LinkedIn 페이지를 방문하여 직원들이 공유한 정보를 확인하거나, 회사에 직접 문의해 보세요.\n",
       "* **직업 포털:** Indeed, Glassdoor와 같은 직업 포털 사이트에서 SolverX의 직원 후기와 복지 혜택 정보를 찾을 수 있습니다.\n",
       "\n",
       "\n",
       "<end_of_turn></td>\n",
       "      <td id=\"T_e9d73_row4_col3\" class=\"data row4 col3\" >SolverX는 설립 이후 2022년에 폐식되었다.<end_of_turn>\n",
       "<pad></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xc6de264f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Category\": [q[\"category\"] for q in questions],\n",
    "    \"Question\": [q[\"question\"] for q in questions],\n",
    "    \"Base Model Answer\": base_responses,\n",
    "    \"Fine-tuned Model Answer\": ft_responses\n",
    "})\n",
    "\n",
    "# Style the DataFrame for better visualization\n",
    "def highlight_diff(row):\n",
    "    styles = [''] * len(row)\n",
    "    if row['Category'] == 'Injected Knowledge':\n",
    "        # Highlight Fine-tuned answer in green for injected knowledge\n",
    "        styles[3] = 'background-color: #d4edda; color: #155724; font-weight: bold;'\n",
    "        styles[2] = 'background-color: #f8d7da; color: #721c24;' # Red for base model failure\n",
    "    elif row['Category'] == 'Hallucination Check':\n",
    "        # Highlight potential hallucination in yellow\n",
    "        styles[3] = 'background-color: #fff3cd; color: #856404;'\n",
    "    return styles\n",
    "\n",
    "# Apply styling\n",
    "styled_df = df.style.apply(highlight_diff, axis=1).set_properties(**{'text-align': 'left', 'white-space': 'pre-wrap'})\n",
    "\n",
    "# Display\n",
    "display(HTML(\"<h3>Comparison Results</h3>\"))\n",
    "display(styled_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
